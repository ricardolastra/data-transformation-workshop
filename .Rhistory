"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
#Quitamos emojis
biblia_corpus <- tm_map(biblia_corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
#Quitamos emojis
biblia_corpus <- tm_map(biblia_corpus, function(x) iconv(x, to='UTF-8', sub='byte'))
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
inspect(biblia_corpus[1:2])
biblia_corpus[[1]]$meta
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
#Quitamos emojis
biblia_corpus <- tm_map(biblia_corpus, function(x) iconv(x, to='UTF-8', sub='byte'))
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
inspect(biblia_corpus[1:2])
biblia_corpus[[1]]$meta
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
#corpus <- tm_map(corpus, iconv(dataSet, 'UTF-8', 'ASCII'))
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte')) #quita emojis
corpus <- tm_map(corpus, iconv(dataSet, 'UTF-8', 'ASCII')) #quita emojis
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte')) #quita emojis
corpus <- tm_map(corpus, iconv(corpus, 'UTF-8', 'ASCII')) #quita emojis
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte')) #quita emojis
corpus <- tm_map(corpus, iconv(enc2utf8(x), sub = "byte")) #quita emojis
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
#corpus <- tm_map(corpus, function(x) iconv(x, to='UTF-8-MAC', sub='byte')) #quita emojis
#corpus <- tm_map(corpus, iconv(enc2utf8(x), sub = "byte")) #quita emojis
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
tm_map(biblia_corpus, function(x) iconv(enc2utf8(x), sub = "byte"))
tm_map(biblia_corpus, function(corpus) iconv(enc2utf8(corpus), sub = "byte"))
biblia_corpus
tm_map(biblia_corpus, function(biblia_corpus) iconv(enc2utf8(biblia_corpus), sub = "byte"))
biblia_corpus
tm_map(biblia_corpus)
tm_map(biblia_corpus, iconv(enc2utf8(), sub = "byte"))
tm_map(biblia_corpus, iconv(enc2utf8(biblia_corpus), sub = "byte"))
DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8")
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(mydata, content_transformer(gsub), pattern="\\W",replace=" ")
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(gsub), pattern="\\W",replace=" ")
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","itido", "or","ltimedia"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_tdm <- TermDocumentMatrix(biblia_corpus)
inspect(biblia_tdm)
#Convert the tdm into a matrix
biblia_m <- as.matrix(biblia_tdm)
head(biblia_m)
#sum rows to get frequency
biblia_words <- sort(rowSums(biblia_m), decreasing = T)
#convert the matrix into a DF to get names and frequencies
biblia_freq <- data.frame(terms = names(biblia_words), num = biblia_words)
head(biblia_freq)
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 75, colors = c( "grey", "orange", "red"))
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
inspect(biblia_corpus[1:2])
biblia_corpus[[1]]$meta
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(gsub), pattern="\\W",replace=" ")
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","niitido", "por","multimedia"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_tdm <- TermDocumentMatrix(biblia_corpus)
inspect(biblia_tdm)
#Convert the tdm into a matrix
biblia_m <- as.matrix(biblia_tdm)
head(biblia_m)
#sum rows to get frequency
biblia_words <- sort(rowSums(biblia_m), decreasing = T)
#convert the matrix into a DF to get names and frequencies
biblia_freq <- data.frame(terms = names(biblia_words), num = biblia_words)
head(biblia_freq)
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 75, colors = c( "grey", "orange", "red"))
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(gsub), pattern="\\W",replace=" ")
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","pocos", "sin","multimedia", "está"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_tdm <- TermDocumentMatrix(biblia_corpus)
inspect(biblia_tdm)
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(gsub), pattern="\\W",replace=" ")
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","pocos", "sin","multimedia", "está", "esta", "nos"
"más"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
inspect(biblia_corpus[1:2])
biblia_corpus[[1]]$meta
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(gsub), pattern="\\W",replace=" ")
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","pocos", "sin","multimedia", "está", "esta", "nos",
"más"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_tdm <- TermDocumentMatrix(biblia_corpus)
inspect(biblia_tdm)
#Convert the tdm into a matrix
biblia_m <- as.matrix(biblia_tdm)
head(biblia_m)
#sum rows to get frequency
biblia_words <- sort(rowSums(biblia_m), decreasing = T)
#convert the matrix into a DF to get names and frequencies
biblia_freq <- data.frame(terms = names(biblia_words), num = biblia_words)
head(biblia_freq)
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 75, colors = c( "grey", "orange", "red"))
biblia_freq
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(gsub), pattern="\\W",replace=" ")
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitido","pocos", "sin","multimedia", "está", "esta", "nos",
"más", "cuando", "hasta"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_tdm <- TermDocumentMatrix(biblia_corpus)
inspect(biblia_tdm)
#Convert the tdm into a matrix
biblia_m <- as.matrix(biblia_tdm)
head(biblia_m)
#sum rows to get frequency
biblia_words <- sort(rowSums(biblia_m), decreasing = T)
#convert the matrix into a DF to get names and frequencies
biblia_freq <- data.frame(terms = names(biblia_words), num = biblia_words)
head(biblia_freq)
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 75, colors = c( "grey", "orange", "red"))
biblia_freq
biblia_corpus <- VCorpus(DirSource("C:/Users/Administrador/Desktop/DOC/WORKSHOP_R/chat", encoding = "UTF-8"),readerControl = list(language = "es-419"))
inspect(biblia_corpus[1:2])
biblia_corpus[[1]]$meta
#Función de funciones de r base y tm
#------------------------------Clean Corpora function-------------------------
clean_corpus <- function(corpus){
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, content_transformer(gsub), pattern="\\W",replace=" ")
#corpus <- tm_map(corpus, content_transformer(replace_abbreviation))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, c(stopwords("en"), "que"
,"los", "por","porque", "mas", "del", "Lety", "las", "para",
"con", "como", "entonces", "pues", "que", "con", "sus",
"también", "todo", "les", "ellos", "lety", "ric", "había",
"todos", "tambien", "lety","vosotros", "gutenbergtm", "fue",
"dicho", "una", "uno", "entre", "este", "esto", "eso", "Ric",
"omitidoe","pocos", "sin","multimedia", "está", "esta", "nos",
"más", "cuando", "hasta"))
return(corpus)
}
#Y cambiamos con la función
biblia_corpus <- clean_corpus(biblia_corpus)
biblia_tdm <- TermDocumentMatrix(biblia_corpus)
inspect(biblia_tdm)
head(biblia_m)
#Convert the tdm into a matrix
biblia_m <- as.matrix(biblia_tdm)
#convert the matrix into a DF to get names and frequencies
biblia_freq <- data.frame(terms = names(biblia_words), num = biblia_words)
head(biblia_freq)
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 45, colors = c( "grey", "orange", "red"))
#sum rows to get frequency
biblia_words <- sort(rowSums(biblia_m), decreasing = T)
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 45, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 45, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 35, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 35, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 35, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 35, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 135, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 85, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "grey", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "black", "purple", "yellow"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "purple", "purple", "yellow"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "purple", "black", "yellow"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "purple", "black", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "blue", "black", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "blue", "black", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 40, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 80, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 50, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 49, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 49, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 49, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 49, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 49, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 49, colors = c( "blue", "orange", "red"))
#Create a wordcloud with the most 100 frequent terms
wordcloud(biblia_freq$terms, biblia_freq$num, max.words = 49, colors = c( "blue", "orange", "red"))
library(dplyr)
biblia_freq2 <- biblia_freq %>%
filter(num>50)
install.packages("stringdist")
library(stringdist)
uniquewords <- unique(as.character(biblia_freq2$terms))
distancewords <- stringdistmatrix(uniquewords,uniquewords,method = "jw")
rownames(distancewords) <- uniquewords
hc <- hclust(as.dist(distancewords))
plot(hc)
rect.hclust(hc,k=20)
rect.hclust(hc,k=15)
hc <- hclust(as.dist(distancewords))
plot(hc)
rect.hclust(hc,k=15)
hclust(as.dist(distancewords)
hclust(as.dist(distancewords))
hclust(as.dist(distancewords))
hc <- hclust(as.dist(distancewords))
plot(hc)
